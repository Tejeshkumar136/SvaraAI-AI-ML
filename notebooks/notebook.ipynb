{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5009822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Ensure a default seed exists if not previously defined\n",
    "if 'SEED' not in globals():\n",
    "    SEED = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc70856",
   "metadata": {},
   "source": [
    "# New dataset pipeline: clean `text.csv`, keep only `text` and `sentiment`, retrain transformer\n",
    "This section loads the new dataset, cleans it, filters to required columns, and fine-tunes the transformer. It also ensures both columns are quoted on save.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c49e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw_shape': (4815, 9), 'columns': ['textID', 'text', 'sentiment', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']}\n"
     ]
    }
   ],
   "source": [
    "# Robust CSV load (handles encoding and delimiter), supports text.csv or test.csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import csv, chardet\n",
    "\n",
    "candidates = [Path('../data/tet.csv'), Path('../data/test.csv')]\n",
    "DATA_NEW = next((p for p in candidates if p.exists()), None)\n",
    "assert DATA_NEW is not None, f\"Dataset not found at {candidates}\"\n",
    "\n",
    "with open(DATA_NEW, 'rb') as f:\n",
    "    enc = chardet.detect(f.read(1_000_000)).get('encoding') or 'utf-8'\n",
    "\n",
    "try:\n",
    "    raw = pd.read_csv(DATA_NEW, dtype=str, encoding=enc, engine='python', sep=None, on_bad_lines='skip')\n",
    "except Exception:\n",
    "    try:\n",
    "        raw = pd.read_csv(DATA_NEW, dtype=str, encoding=enc, engine='python', sep=',', on_bad_lines='skip')\n",
    "    except Exception:\n",
    "        raw = pd.read_csv(DATA_NEW, dtype=str, encoding=enc, engine='python', sep='\\t', on_bad_lines='skip')\n",
    "\n",
    "print({\"raw_shape\": raw.shape, \"columns\": list(raw.columns)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68cd5f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed with encoding=utf-8: 'utf-8' codec can't decode byte 0xb2 in position 13: invalid start byte\n",
      "Loaded with encoding=ISO-8859-1\n",
      "{'raw_shape': (4815, 9), 'columns': ['textID', 'text', 'sentiment', 'Time of Tweet', 'Age of User', 'Country', 'Population -2020', 'Land Area (Km²)', 'Density (P/Km²)']}\n",
      "{'clean_shape': (3534, 2), 'label_counts': {'neutral': 1430, 'positive': 1103, 'negative': 1001}}\n",
      "Cleaned dataset saved at: ..\\data\\clean_text.csv\n"
     ]
    }
   ],
   "source": [
    "# Load and clean new dataset (test.csv)\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_NEW = Path('../data/test.csv')  # your dataset\n",
    "assert DATA_NEW.exists(), f\"Dataset not found at {DATA_NEW}\"\n",
    "\n",
    "# Try multiple encodings until one works\n",
    "encodings = [\"utf-8\", \"ISO-8859-1\", \"cp1252\"]\n",
    "raw = None\n",
    "for enc in encodings:\n",
    "    try:\n",
    "        raw = pd.read_csv(DATA_NEW, dtype=str, encoding=enc, on_bad_lines=\"skip\")\n",
    "        print(f\"Loaded with encoding={enc}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Failed with encoding={enc}: {e}\")\n",
    "\n",
    "assert raw is not None, \"Could not load CSV with tried encodings\"\n",
    "print({\"raw_shape\": raw.shape, \"columns\": list(raw.columns)})\n",
    "\n",
    "# Standardize column names to expected ones\n",
    "text_col = next((c for c in raw.columns if c.lower().strip() in {\"text\", \"message\", \"reply\", \"content\"}), None)\n",
    "sent_col = next((c for c in raw.columns if c.lower().strip() in {\"sentiment\", \"label\", \"class\", \"target\"}), None)\n",
    "assert text_col and sent_col, \"Could not detect text/sentiment columns\"\n",
    "\n",
    "df = raw[[text_col, sent_col]].rename(columns={text_col: \"text\", sent_col: \"sentiment\"})\n",
    "\n",
    "# Clean text\n",
    "def clean_text(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    return \" \".join(s.split())\n",
    "\n",
    "# Normalize labels\n",
    "def normalize_label(s):\n",
    "    if not isinstance(s, str):\n",
    "        return \"neutral\"\n",
    "    s = s.strip().lower()\n",
    "    mapping = {\n",
    "        \"pos\": \"positive\", \"+\": \"positive\", \"1\": \"positive\",\n",
    "        \"neg\": \"negative\", \"-\": \"negative\",\n",
    "        \"0\": \"neutral\", \"neu\": \"neutral\"\n",
    "    }\n",
    "    if s in mapping:\n",
    "        return mapping[s]\n",
    "    if \"posit\" in s: return \"positive\"\n",
    "    if \"negat\" in s: return \"negative\"\n",
    "    if \"neutral\" in s or s == \"\": return \"neutral\"\n",
    "    return s\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"sentiment\"] = df[\"sentiment\"].apply(normalize_label)\n",
    "\n",
    "# Keep only allowed labels\n",
    "allowed = {\"negative\", \"neutral\", \"positive\"}\n",
    "df = df.dropna(subset=[\"text\", \"sentiment\"])\n",
    "df = df[df[\"sentiment\"].isin(allowed)]\n",
    "df = df[df[\"text\"].str.len() > 0]\n",
    "\n",
    "print({\"clean_shape\": df.shape, \"label_counts\": df[\"sentiment\"].value_counts().to_dict()})\n",
    "\n",
    "# Save cleaned file (with quotes)\n",
    "CLEAN_PATH = Path(\"../data/clean_text.csv\")\n",
    "df.to_csv(CLEAN_PATH, index=False, quoting=1, encoding=\"utf-8\")\n",
    "print(f\"Cleaned dataset saved at: {CLEAN_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "587389d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_train': 2827, 'n_test': 707, 'labels': {0: 'negative', 1: 'neutral', 2: 'positive'}}\n"
     ]
    }
   ],
   "source": [
    "# Train/test split on cleaned data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(sorted(df['sentiment'].unique()))}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'].tolist(),\n",
    "    df['sentiment'].map(label2id).tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['sentiment'].tolist() if df['sentiment'].value_counts().min() >= 2 else None,\n",
    ")\n",
    "print({\"n_train\": len(X_train), \"n_test\": len(X_test), \"labels\": id2label})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cceb81d4",
   "metadata": {},
   "source": [
    "# SvaraAI Reply Classification Notebook\n",
    "\n",
    "This notebook trains two models for classifying email replies: a TF-IDF + Logistic Regression baseline and a fine-tuned `distilbert-base-uncased` transformer. It evaluates both (accuracy, F1) and saves the best model for the API in `../models/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9438ff8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pickle\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = Path('../data/clean_text.csv')  # replace with provided dataset path if different\n",
    "MODELS_DIR = Path('../models')\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "705a52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, '\"Recession hit Veronique Branquinho, she has to quit her company, such a shame!\",\"negative\"'), (9, '\"soooooo wish i could, but im in school and myspace is completely blocked\",\"negative\"'), (15, '\"I`m in VA for the weekend, my youngest son turns 2 tomorrow......it makes me kinda sad, he is getting so big, check out my twipics\",\"negative\"'), (17, '\"So hot today =_= don`t like it and i hate my new timetable, having such a bad week\",\"negative\"'), (21, '\"I`m going into a spiritual stagnentation, its exploding my ego!. I now realise, i`m not all that great. and I`m ok with that.\",\"neutral\"'), (24, '\"... need retail therapy, bad. AHHH.....gimme money geebus\",\"negative\"'), (28, '\"hey peoples, dont you just hate being grounded haha, im just sat eating an apple and watching death note (some anime)\",\"neutral\"'), (29, '\"Huh, another ScarePoint coding Sunday\",\"neutral\"'), (31, '\"No AC, the fan doesnt swing our way ... we are sweating it out on a hot humid day\",\"negative\"'), (34, '\"There is a faux gothy chick looking at me, sorry I am not going to camden and I like pop-punk and jimmy eat world\",\"neutral\"')]\n"
     ]
    }
   ],
   "source": [
    "bad_rows = []\n",
    "with open(DATA_PATH, encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, start=1):\n",
    "        if line.count(\",\") > 1:  # more than \"text\",\"label\"\n",
    "            bad_rows.append((i, line.strip()))\n",
    "\n",
    "print(bad_rows[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaf14438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3534, Train: 2827, Test: 707\n",
      "Label mapping: {'negative': 0, 'neutral': 1, 'positive': 2}\n"
     ]
    }
   ],
   "source": [
    "# Load & preprocess data\n",
    "\n",
    "def clean_text(s: str) -> str:\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    return s\n",
    "\n",
    "raw = pd.read_csv(DATA_PATH)\n",
    "raw = raw.dropna(subset=['text', 'sentiment']).copy()\n",
    "raw['text'] = raw['text'].apply(clean_text)\n",
    "\n",
    "label2id = {l: i for i, l in enumerate(sorted(raw['sentiment'].unique()))}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "\n",
    "# Handle tiny datasets: only stratify if every class has at least 2 samples\n",
    "# and the test set will have at least 1 sample per class\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    raw['text'].tolist(),\n",
    "    raw['sentiment'].map(label2id).tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=raw['sentiment'],\n",
    ")\n",
    "print(f\"Dataset size: {len(raw)}, Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(\"Label mapping:\", label2id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "170bf972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline_accuracy': 0.6577086280056577, 'baseline_f1_macro': 0.6629919586148564}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      0.69      0.67       200\n",
      "     neutral       0.61      0.60      0.61       286\n",
      "    positive       0.72      0.69      0.71       221\n",
      "\n",
      "    accuracy                           0.66       707\n",
      "   macro avg       0.66      0.66      0.66       707\n",
      "weighted avg       0.66      0.66      0.66       707\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline: TF-IDF + Logistic Regression\n",
    "baseline = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(lowercase=True, ngram_range=(1, 2), min_df=1)),\n",
    "    (\"logreg\", LogisticRegression(max_iter=200, class_weight=\"balanced\", random_state=SEED)),\n",
    "])\n",
    "\n",
    "baseline.fit(X_train, y_train)\n",
    "\n",
    "pred = baseline.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred)\n",
    "f1 = f1_score(y_test, pred, average='macro')\n",
    "print({\"baseline_accuracy\": acc, \"baseline_f1_macro\": f1})\n",
    "\n",
    "# Align report labels to those present in y_test to avoid mismatches on tiny splits\n",
    "labels_present = sorted(set(y_test))\n",
    "target_names = [id2label[i] for i in labels_present]\n",
    "print(classification_report(y_test, pred, labels=labels_present, target_names=target_names))\n",
    "\n",
    "# Save baseline\n",
    "with open(MODELS_DIR / 'baseline.pkl', 'wb') as f:\n",
    "    pickle.dump(baseline, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "836fc1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 1.0}\n",
      "{'saved': '..\\\\models\\\\transformer\\\\temperature.json'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejes\\AppData\\Local\\Temp\\ipykernel_53336\\2206607261.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  t = float(np.exp(log_T))  # ensure positivity\n"
     ]
    }
   ],
   "source": [
    "# Temperature scaling: learn temperature T on validation set and save for API use\n",
    "# Requires: model, device, and val_loader from previous CSV fine-tuning cell\n",
    "\n",
    "import json, numpy as np, torch\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "logits_list, labels_list = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        y = batch[\"labels\"].to(device)\n",
    "        x = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "        logits = model(**x).logits\n",
    "        logits_list.append(logits.cpu())\n",
    "        labels_list.append(y.cpu())\n",
    "\n",
    "logits = torch.cat(logits_list).numpy()\n",
    "labels = torch.cat(labels_list).numpy()\n",
    "\n",
    "def nll_loss(log_T):\n",
    "    t = float(np.exp(log_T))  # ensure positivity\n",
    "    z = logits / t\n",
    "    z = z - z.max(axis=1, keepdims=True)\n",
    "    p = np.exp(z) / np.exp(z).sum(axis=1, keepdims=True)\n",
    "    eps = 1e-12\n",
    "    return -np.log(p[np.arange(len(labels)), labels] + eps).mean()\n",
    "\n",
    "res = minimize(nll_loss, x0=np.array([0.0]), method=\"L-BFGS-B\")\n",
    "T = float(np.exp(res.x[0]))\n",
    "print({\"temperature\": T})\n",
    "\n",
    "(temp_dir := (MODELS_DIR / \"transformer\")).mkdir(parents=True, exist_ok=True)\n",
    "with open(temp_dir / \"temperature.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"temperature\": T}, f)\n",
    "\n",
    "print({\"saved\": str(temp_dir / \"temperature.json\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f27e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'baseline': {'accuracy': 0.6577086280056577, 'f1_macro': 0.6629919586148564}, 'transformer': {'accuracy': 0.7369165487977369, 'f1_macro': 0.7414003009830316}}\n",
      "Best model: transformer\n"
     ]
    }
   ],
   "source": [
    "# Comparison & selection\n",
    "from pathlib import Path\n",
    "\n",
    "# Load baseline metrics (already printed). Transformer metrics in `metrics`.\n",
    "# For a tiny dataset, metrics may be unstable. We'll choose transformer if f1 improves.\n",
    "\n",
    "baseline_metrics = {\"accuracy\": acc, \"f1_macro\": f1}\n",
    "transformer_metrics = {\"accuracy\": metrics.get('eval_accuracy', 0.0), \"f1_macro\": metrics.get('eval_f1_macro', 0.0)}\n",
    "print({\"baseline\": baseline_metrics, \"transformer\": transformer_metrics})\n",
    "\n",
    "best = 'transformer' if transformer_metrics['f1_macro'] >= baseline_metrics['f1_macro'] else 'baseline'\n",
    "print(f\"Best model: {best}\")\n",
    "\n",
    "# The API checks `models/transformer/` first, else `models/baseline.pkl`.\n",
    "# Nothing else needed here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a8abc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2827/2827 [00:00<00:00, 19840.33 examples/s]\n",
      "Map: 100%|██████████| 707/707 [00:00<00:00, 18636.66 examples/s]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 1, 'train_loss': 0.7723835450781267}\n",
      "{'eval_accuracy': 0.7425742574257426, 'eval_f1_macro': 0.745325597661452}\n",
      "{'epoch': 2, 'train_loss': 0.5008132660203735}\n",
      "{'eval_accuracy': 0.7722772277227723, 'eval_f1_macro': 0.7756110518258855}\n",
      "{'epoch': 3, 'train_loss': 0.3591410228719482}\n",
      "{'eval_accuracy': 0.7652050919377652, 'eval_f1_macro': 0.7690384542536121}\n",
      "{'epoch': 4, 'train_loss': 0.2396646352474299}\n",
      "{'eval_accuracy': 0.7538896746817539, 'eval_f1_macro': 0.7583142139897424}\n",
      "{'early_stopping': True, 'best_f1_macro': 0.7756110518258855}\n",
      "{'best_f1_macro': 0.7756110518258855, 'saved_to': '..\\\\models\\\\transformer'}\n"
     ]
    }
   ],
   "source": [
    "# Improved RoBERTa fine-tuning with class-weighted loss and early stopping\n",
    "# Uses X_train, y_train, X_test, y_test, id2label, label2id from earlier cells\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Choose a lighter model if disk is tight\n",
    "model_name = os.environ.get('LIGHT_MODEL', 'distilroberta-base')  # fallback lighter than roberta-base\n",
    "max_length = 160\n",
    "train_batch_size = 16\n",
    "eval_batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "weight_decay = 0.01\n",
    "patience = 2\n",
    "\n",
    "# Use local cache to avoid filling system disk\n",
    "cache_dir = str(Path('../models/hf_cache'))\n",
    "os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "\n",
    "# Dataset & tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir)\n",
    "train_ds = Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "eval_ds = Dataset.from_dict({'text': X_test, 'label': y_test})\n",
    "\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch['text'], truncation=True, max_length=max_length)\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=['text'])\n",
    "eval_tok = eval_ds.map(tokenize_fn, batched=True, remove_columns=['text'])\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "num_labels = len(label2id)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Class weights for imbalance\n",
    "_, counts = np.unique(y_train, return_counts=True)\n",
    "class_weights = torch.tensor((counts.sum() / (counts * len(counts))).astype(np.float32), device=device)\n",
    "\n",
    "# Metrics\n",
    "metric_acc = evaluate.load('accuracy')\n",
    "metric_f1 = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(axis=-1)\n",
    "    acc = metric_acc.compute(predictions=preds, references=labels)['accuracy']\n",
    "    f1 = metric_f1.compute(predictions=preds, references=labels, average='macro')['f1']\n",
    "    return {'accuracy': acc, 'f1_macro': f1}\n",
    "\n",
    "# Custom Trainer to apply class-weighted CE\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels, weight=class_weights)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Manual training loop with early stopping (compat with older transformers)\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Set torch format\n",
    "train_tok.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "eval_tok.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n",
    "train_loader = DataLoader(train_tok, batch_size=train_batch_size, shuffle=True, collate_fn=collator)\n",
    "eval_loader = DataLoader(eval_tok, batch_size=eval_batch_size, shuffle=False, collate_fn=collator)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "best_f1 = -1.0\n",
    "no_improve = 0\n",
    "save_dir = Path('../models/transformer')\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        if 'label' in batch and 'labels' not in batch:\n",
    "            batch['labels'] = batch.pop('label')\n",
    "        outputs = model(**{k: v for k, v in batch.items() if k != 'labels'})\n",
    "        logits = outputs.logits\n",
    "        loss = torch.nn.functional.cross_entropy(logits, batch['labels'], weight=class_weights)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += float(loss.detach().cpu())\n",
    "    print({'epoch': epoch + 1, 'train_loss': total_loss / max(1, len(train_loader))})\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            if 'label' in batch and 'labels' not in batch:\n",
    "                batch['labels'] = batch.pop('label')\n",
    "            labels = batch['labels'].to(device)\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != 'labels'}\n",
    "            logits = model(**inputs).logits\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            all_preds.extend(preds.detach().cpu().tolist())\n",
    "            all_labels.extend(labels.detach().cpu().tolist())\n",
    "\n",
    "    acc = metric_acc.compute(predictions=all_preds, references=all_labels)['accuracy']\n",
    "    f1 = metric_f1.compute(predictions=all_preds, references=all_labels, average='macro')['f1']\n",
    "    print({'eval_accuracy': acc, 'eval_f1_macro': f1})\n",
    "\n",
    "    # Early stopping + save best\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        no_improve = 0\n",
    "        model.save_pretrained(str(save_dir))\n",
    "        if not (save_dir / 'tokenizer_config.json').exists():\n",
    "            tokenizer.save_pretrained(str(save_dir))\n",
    "    else:\n",
    "        no_improve += 1\n",
    "        if no_improve >= patience:\n",
    "            print({'early_stopping': True, 'best_f1_macro': best_f1})\n",
    "            break\n",
    "\n",
    "print({'best_f1_macro': best_f1, 'saved_to': str(save_dir)})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
